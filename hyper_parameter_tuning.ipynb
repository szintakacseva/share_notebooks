{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a1bdbd-67fb-441d-9fcd-c3bc61297d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c0d933-8637-473f-959f-a44977dc74b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# References\n",
    "https://medium.com/towards-data-science/hyperopt-demystified-3e14006eb6fa #hyperopt for XGBoost\n",
    "https://xgboost.readthedocs.io/en/stable/parameter.html #xgboost parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c47696-ca4f-4285-8a11-bda421f56889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tags\n",
    "hyperopt, xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4a6a16-bf62-4772-8afc-7c0170d4117e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from numpy.random import normal\n",
    "from numpy import hstack\n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_importance, plot_tree\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "from utils import tab_data, interactive_segment_numeric_by_categoricals, segment_numeric_by_categoricals\n",
    "\n",
    "\n",
    "# settings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#print all rows of a df in ipython shell \n",
    "pd.set_option('display.max_rows', None)\n",
    "#print all columns of a df in ipython shell \n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# optional\n",
    "pd.set_option('display.max_columns',100)\n",
    "sns.set_style('darkgrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fd697e-f54d-495f-a811-b0d9288ab17a",
   "metadata": {},
   "source": [
    "## TOC:\n",
    "* [XGBoost for Regression](#first-bullet)\n",
    "* [Second Bullet Header](#second-bullet)\n",
    "* [Third Bullet Header](#third-bullet)\n",
    "* [Fourth Bullet Header](#fourt-bullet)\n",
    "* [Miscellous Bullet Header](#miscellous-bullet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e44235db-777c-41ca-99e6-536e8faf86ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hyperopt\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6607ebfe-6a7c-42d6-9a69-90e6cf5bb56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install hyperopt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c19e18-0d71-4839-b547-1ea3a7fd1e4a",
   "metadata": {},
   "source": [
    "## XGBoost for Regression <a class=\"anchor\" id=\"first-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba31d211-e26c-4999-93dc-edd6045d68a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1: Initialize space or a required range of values\n",
    "\n",
    "space={'max_depth': hp.quniform(\"max_depth\", 3, 18, 1),\n",
    "        'gamma': hp.uniform ('gamma', 1,9),\n",
    "        'reg_alpha' : hp.quniform('reg_alpha', 40,180,1),\n",
    "        'reg_lambda' : hp.uniform('reg_lambda', 0,1),\n",
    "        'colsample_bytree' : hp.uniform('colsample_bytree', 0.5,1),\n",
    "        'min_child_weight' : hp.quniform('min_child_weight', 0, 10, 1),\n",
    "        'n_estimators': 180\n",
    "      }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad362eb0-61ed-493b-b271-01a53de445c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Define objective function Regression: \n",
    "def hyperparameter_tuning(space):\n",
    "    model=xgb.XGBRegressor(n_estimators =space['n_estimators'], max_depth = int(space['max_depth']), gamma = space['gamma'],\n",
    "                         reg_alpha = int(space['reg_alpha'],min_child_weight=space['min_child_weight'],\n",
    "                         colsample_bytree=space['colsample_bytree']))\n",
    "    \n",
    "    evaluation = [( x_train, y_train), ( x_test, y_test)]\n",
    "    \n",
    "    model.fit(x_train, y_train,\n",
    "            eval_set=evaluation, eval_metric=\"rmse\",\n",
    "            early_stopping_rounds=10,verbose=False)\n",
    "\n",
    "    pred = model.predict(x_test)\n",
    "    mse= mean_squared_error(y_test, pred)\n",
    "    print (\"SCORE:\", mse)\n",
    "    #change the metric if you like\n",
    "    return {'loss':mse, 'status': STATUS_OK, 'model': model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507b3430-aead-4f81-a7ea-042bf8acd859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Run Hyperopt function\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(fn=hyperparameter_tuning,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=100,\n",
    "            trials=trials)\n",
    "\n",
    "print (best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59eb097-7d9b-4934-a275-3690db019803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All in one step\n",
    "\n",
    "import hyperopt\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "\n",
    "#Step 1: Initialize space or a required range of values\n",
    "\n",
    "space={'max_depth': hp.quniform(\"max_depth\", 3, 18, 1),\n",
    "        'gamma': hp.uniform ('gamma', 1,9),\n",
    "        'reg_alpha' : hp.quniform('reg_alpha', 40,180,1),\n",
    "        'reg_lambda' : hp.uniform('reg_lambda', 0,1),\n",
    "        'colsample_bytree' : hp.uniform('colsample_bytree', 0.5,1),\n",
    "        'min_child_weight' : hp.quniform('min_child_weight', 0, 10, 1),\n",
    "        'n_estimators': 180\n",
    "      }\n",
    "\n",
    "# Step 2: Define objective function Regression: \n",
    "def hyperparameter_tuning(space):\n",
    "    model=xgb.XGBRegressor(n_estimators =space['n_estimators'], max_depth = int(space['max_depth']), gamma = space['gamma'],\n",
    "                         reg_alpha = int(space['reg_alpha'],min_child_weight=space['min_child_weight'],\n",
    "                         colsample_bytree=space['colsample_bytree']))\n",
    "    \n",
    "    evaluation = [( x_train, y_train), ( x_test, y_test)]\n",
    "    \n",
    "    model.fit(x_train, y_train,\n",
    "            eval_set=evaluation, eval_metric=\"rmse\",\n",
    "            early_stopping_rounds=10,verbose=False)\n",
    "\n",
    "    pred = model.predict(x_test)\n",
    "    mse= mean_squared_error(y_test, pred)\n",
    "    print (\"SCORE:\", mse)\n",
    "    #change the metric if you like\n",
    "    return {'loss':mse, 'status': STATUS_OK, 'model': model}\n",
    "\n",
    "# Step 3: Run Hyperopt function\n",
    "trials = Trials()\n",
    "best = fmin(fn=hyperparameter_tuning,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=100,\n",
    "            trials=trials)\n",
    "\n",
    "print (best)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
